{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TOLIMAN","text":"<p>The goal of the TOLIMAN mission is to answer the question: is there a planet around Alpha Centauri? The critical advance represented by the TOLIMAN  telescope is its ability to assess a specific star. Until now telescopes have been designed to survey many stars and confirm (with biases) which ones may  have exoplanets. None have chosen a star and tried to resolutely and without  question find all and any exoplanets in orbit. </p>"},{"location":"CHANGELOG/","title":"CHANGELOG","text":""},{"location":"CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#v003-2023-01-18","title":"v0.0.3 - 2023-01-18","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#v002-2023-01-18","title":"v0.0.2 - 2023-01-18","text":"<p>Full Changelog</p>"},{"location":"CONTRIBUTING/","title":"CONTRIBUTING","text":"<p>The <code>toliman</code> package is managed using <code>poetry</code> and it is helpful if you also  have <code>conda</code> installed. Firstly check you <code>python</code> version, which can be done  using by typing <code>python --version</code> in the command prompt. You will need to have <code>python &gt;= 3.7</code> installed but it is recommended that you use <code>python == 3.10</code>.  The package development was done using <code>python == 3.10.8</code>, which was the  highest supported <code>python</code> for <code>conda</code> at the time of development. </p> <p>Once you have checked your <code>python</code> installation is up to date, we can install  <code>poetry</code>. If you are using <code>conda</code> then I would recommend completing all these  steps in a fresh <code>conda</code> environment (you can create a new environment using <code>conda create -n your-name-here</code>). The <code>poetry</code> documentation explains how to install  <code>poetry</code> which needs to be done using the system equivalent of <code>curl</code>.  Check <code>poetry</code> is installed by running <code>poetry --version</code>. The package was  developed using <code>poetry == 1.3.2</code>. </p> <p>Now that <code>poetry</code> is installed you can use <code>git</code> to clone the repository. If  you do not have <code>git</code> installed, detailed instructions can be found in the  <code>git</code> documentation. As with <code>poetry</code> and <code>python</code> you can check the version of <code>git</code> that is  installed using <code>git --version</code>. Once <code>git</code> is installed run <code>git clone https://github.com/ConaireD/TolimanWIP</code> to import the repository onto your  machine. </p> <p>This process should have cloned the project into a new folder called  <code>TolimanWIP</code>. Move into that directory using <code>cd</code> and then run <code>poetry install</code>. This will take some time as <code>poetry</code> resolves the packages dependencies. So go grab a coffee sit back and relax while it runs (should take about 1-10min depending on your connection). You can now make changes to the source code. If you want these changes to join the <code>git</code> repository you will instead need to create a <code>fork</code> (unless you have write permission). </p> <p>The full installation and setup process on Ubuntu, without <code>git</code> or <code>poetry</code> pre-installed, but with <code>conda</code> looks like: <pre><code>$ conda create -n toliman python==3.10.8\n$ conda activate toliman\n$ python --version\n$ curl -sSL https://install.python-poetry.org | python3 -\n$ poetry --version\n$ sudo apt update\n$ sudo apt install git\n$ git version \n$ git clone https://github.com/ConaireD/TolimanWIP\n$ cd TolimanWIP\n$ poetry install </code></pre> If you are planning to change the code, then be aware that we are using <code>black</code> as an auto-format-tool on both the tests and the source code. Before pushing make sure that you have run the tests by invoking <code>pytest</code> and formatted the code  using <code>black</code>. </p> <p>Externally, we have a few other recommendations. Where it makes sense to do so  use <code>from package import ...</code> rather than <code>import package; package.(...)</code> but this is not a strict rule and is just a guideline. To get updates from the  repository run <code>git pull</code> and then re-install using <code>poetry install</code>. Note, it should be much faster after the first time because <code>poetry</code> has already  installed all the dependencies.</p>"},{"location":"INSTALLATION/","title":"INSTALLATION","text":"<p>Hi there, the <code>toliman</code> package is not particularly complex, but the development environment uses lots of modern tools. As a result it not  unlikely that the most difficult part of using <code>toliman</code> will be setting  it up. This guide should walk you through how to set up <code>toliman</code> and  also provides basic guides to using the development tools. We are developing  <code>toliman</code> using <code>git</code> integrated to <code>github</code> via <code>gh</code>, the <code>github</code> command line interface (CLI). <code>toliman</code> is obviously a <code>python</code> package, and we  recommend using the <code>anaconda</code> distribution. <code>poetry</code> is a dependancy  managment tool for package development that behaves a lot like <code>cargo</code> for  those who are familiar. We have used <code>poetry</code> to develop <code>toliman</code>. Our  tests are written using the <code>pytest</code> framework, although hopefully, you  will only need to run our tests and not edit them. That depends on how well we have done our job. Finally, we render our documentation, which you are currently reading using <code>mkdocs</code>. </p>"},{"location":"INSTALLATION/#git","title":"Git","text":"<p>As a developer you have most likely heard of <code>git</code>. It is a version control system, which allows you to revist earlier revisions of the package via a  <code>commit</code> system. In short, when you make changes to a file the changes are  tracked by line so that they can be undone and re-applied at will. As well as  the core <code>commit</code> feature, I described earlier it also allows for prototyping  outside the <code>main</code> distribution of the package via <code>branch</code>es. </p>"},{"location":"INSTALLATION/#installing-git","title":"Installing Git","text":"<p><code>git</code> can be downloaded from their website. However, if you are using a unix based operating system (MacOs/Linux), you  can install <code>git</code> using your package manager, be it <code>brew</code> or <code>apt/apt-get</code>. You can verify that <code>git</code> is installed using <code>git version</code>.</p>"},{"location":"INSTALLATION/#using-git","title":"Using Git","text":"<p><code>git</code> was originally designed to be a tool for making version control  systems. As a result, <code>git</code> commands are divided into two layers; porcelain  commands and plumbing commands. Almost never will you need to use a  plumbing command, as these are the commands that were designed for implementing  version control systems. The porcelain commands represent the <code>git</code> version  control system, which the user normally interacts with. </p> <p>There are less than ten <code>git</code> commands that you will use in your regular  workflow. Primarily, you will use <code>git add</code> and <code>git commit</code>. This pair of  commands is used to create a \"new version\" by means of a <code>commit</code>. Once, you have changed a file, or a set of files <code>stage</code> them using <code>git add  path/to/file</code> (or <code>git add .</code>) to <code>stage</code> all the changes in the current  directory. The <code>git status</code> command can be used to view what files are  changed and staged. <code>git diff path/to/file</code> can be used to view the un<code>commit</code>ed changes to a file (or <code>git diff</code> for all un<code>commit</code>ed changes). Once you  have <code>stage</code>d changes you can <code>commit</code> them using <code>git commit</code>. A commit is  normally associated with a message to explain the purpose of the commit.  This forces you to plan your development in small chunks. An ideal <code>commit</code> message should be a simple sentence; for example, <code>git commit -m \"Updating the installation guide\"</code>. This is obviously an idealisation and by no means what actually happens. </p> <p>Once you have a minimum viable product, it makes sense to prototype new  features without changing the <code>main</code> version of the code. <code>git</code> provides  the <code>branch</code> feature to facilate this kind of development. There is ongoing debate about the validity of so called \"continuous integration\" workflows in AGILE development, but I'll leave such naval gazing to the pros. To  create a new <code>branch</code> use <code>git branch name</code>. While there is no enforced  conventions I'm aware of for naming <code>branch</code>es, I like to use descriptive, lower case, and hyphon separated names. For example, <code>git branch  installion-guide</code>. To switch branches use either <code>git checkout</code> or <code>git switch</code> both taking the <code>branch</code> name as an argument. <code>git checkout</code> is a more general command, so I recommend using <code>git switch</code>. <code>branch</code>es can be made from any  <code>branch</code>, not just <code>main</code>. Once you are happy with the changes on a <code>branch</code>  you can integrate into another target <code>branch</code> using <code>git switch target</code> then  <code>git merge development</code>, where <code>development</code> is the <code>branch</code> you were developing on.</p> <p>On paper <code>git</code> sounds like a very linear tool, meant to guarantee saftey.  However, in the wild it is possible for very many curve balls to arise.  Not the least of these is <code>merge</code> conflicts. These arise when two different  versions of the history of a file both contain changes to the same line.  The simplest way to produce a merge conflict is via the following <code>bash</code>  script.</p> Example<pre><code>(home) user@User-HP ~/Documents$ mkdir gmc\n(home) user@User-HP ~/Documents$ cd gmc\n(home) user@User-HP ~/Documents/gmc$ git init .\n(home) user@User-HP ~/Documents/gmc$ touch hello.txt\n(home) user@User-HP ~/Documents/gmc$ git add hello.txt\n(home) user@User-HP ~/Documents/gmc$ git commit -m \"Creating \\`hello.txt\\` to demonstrate a \\`merge\\` commit.\"\n(home) user@User-HP ~/Documents/gmc$ git branch\n* main\n(home) ~/Documents/gmc$ git branch conflict\n(home) ~/Documents/gmc$ git branch \n* main\nconflict\n(home) ~/Documents/gmc$ echo \"Hello world!\" &gt; hello.txt\n(home) ~/Documents/gmc$ git add hello.txt\n(home) ~/Documents/gmc$ git commit -m \"Creating one version of \\`hello.txt\\`.\" (home) ~/Documents/gmc$ git switch conflict\n(home) ~/Documents/gmc$ git branch\nmain\n* conflict\n(home) ~/Documents/gmc$ echo \"Goodbye world!\" &gt; hello.txt\n(home) ~/Documents/gmc$ git add hello.txt\n(home) ~/Documents/gmc$ git commit -m \"Creating another version of \\`hello.txt\\`.\"\n(home) ~/Documents/gmc$ git switch main\n(home) ~/Documents/gmc$ git branch \n* main\nconflict\n(home) ~/Documents/git-merge-conflict$ git merge conflict\nAuto-merging hello.txt\nCONFLICT (content): Merge conflict in hello.txt\nAutomatic merge failed; fix conflicts and then commit the result.\n(home) ~/Documents/gmc$ git diff hello.txt \ndiff --cc hello.txt\nindex cd08755,7713dc9..0000000\n--- a/hello.txt\n+++ b/hello.txt\n@@@ -1,1 -1,1 +1,5 @@@\n++&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n +Hello world!\n++=======\n+ Goodbye world!\n++&gt;&gt;&gt;&gt;&gt;&gt;&gt; conflict\n</code></pre> <p>The <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code>, <code>=======</code> and <code>&gt;&gt;&gt;&gt;&gt;&gt; conflict</code> are automatically  inserted into the file by <code>git</code>. <code>HEAD</code> is an internal pointer that  references the current <code>branch</code>, in this case <code>main</code>. <code>conflict</code> is the  <code>branch</code> that we are trying to <code>merge</code>. The equals signs divide the two  different versions of the changed contents of the file. Now we would  have to manually chose, what version we wanted to keep <code>conflict</code> of  <code>main</code> and then <code>commit</code> that version to the history. Alternatively you  can run <code>git merge --abort</code> to abandon the <code>merge</code> and fix up the <code>branch</code>es individually.</p> <p>We also need to know how to view and access our <code>commit</code> history. The  best way to view it is using <code>git log</code>, which can take and <code>-n</code> argument to show only the most recent <code>n</code> <code>commit</code>s. If you want to see what changes are in a <code>commit</code> then you can use <code>git show commit_hash</code>. <code>commit</code> hashes  are tricky to work with since they are long and complex. It is often much  easier to reference a commit by how far away it is from the current <code>HEAD</code>. For example, <code>git show HEAD~n</code> will show a <code>commit</code> <code>n</code> away from the most recent <code>commit</code>. To <code>revert</code> a commit (undo the changes) you can use <code>git  revert commit_hash</code>. This will automatically generate a commit message, but you may edit it if you wish. <code>git reset --soft HEAD~</code> will undo the most  recent commit keeping the changes available to stage and commit later.  <code>git restore</code> can be used to unstage changes. </p> <p>While <code>branch</code>ing and <code>commit</code>ing are by far the most important tools to  understand when using <code>git</code>, there are many other features that can be  explored. </p>"},{"location":"INSTALLATION/#plugins","title":"Plugins","text":"<p><code>git</code> is a very widely used tool and as a result developers and businesses  have produced tools that plug into <code>git</code> adding additional features and/or  making it easier to use. We use two different plugins in our development  stratergy: <code>git filter-repo</code> and <code>git lfs</code>. Both of these can be used to  reduce disk usage by changing the way that <code>git</code> deals with large files. </p>"},{"location":"INSTALLATION/#git-filter-repo","title":"Git Filter Repo","text":"<p>While we use <code>git filter-repo</code> to manage large files, it is a very versatile tool that is primarily for disk-space optimisation allowing you to re-write  <code>git</code> histories. In our case we use <code>git filter-repo</code> to write large files  out of the <code>git</code> history. To install <code>git filter-repo</code> you can use your  package manager provided. If this does not work the <code>git filter-repo</code> website provides a detailed guide. You will need to have both <code>git</code> and <code>python</code>  installed before you can install <code>git filter-repo</code>. </p> <p>There is a high chance you will not need <code>git filter-repo</code> in your development. However, it is handy to know how to use when dealing with <code>git</code> in scientific  settings. The basic usage is <code>git filter-repo --invert-paths --path  I/want/to/remove/this/file/from/the/history</code>. The makers of <code>git filter-repo</code> chose to specify the paths to keep rather than those to remove. This is why  <code>--invert-paths</code> is necessary in the former snippet. I was surprised when I  first used this plugin because it also deletes the file not just the  files history. I would recommend using <code>git filter-repo --dry-run</code> before executing your commands as a saftey measure. Since the history is changed you cannot <code>revert</code> to the same earlier state.</p> <p>Earlier I discussed <code>git merge</code> conflicts, what caused them and how to  resolve them. When using <code>git filter-repo</code> <code>merge</code> conflicts cannot arrise because internally <code>git</code> sees two entirely different histories. As a result if you use <code>git filter-repo</code> to change the history of a <code>branch</code> any merges of that <code>branch</code> with other <code>branch</code>es must be forced using <code>git merge --force</code>  or <code>git merge -f</code>. It is usually best to use <code>git filter-repo</code> on a resh  <code>branch</code>, check it worked and then immediately <code>merge</code> it into <code>main</code>.  Otherwise, <code>merge</code> conflicts that might have been important can be missed.</p> Example<pre><code>(home) user@User-HP ~/Documents$ mkdir gfr\n(home) user@User-HP ~/Documents$ cd gfr\n(home) user@User-HP ~/Documents/gfr$ git init .\n(home) user@User-HP ~/Documents/gfr$ touch big_file.txt\n(home) user@User-HP ~/Documents/gfr$ git add big_file.txt\n(home) user@User-HP ~/Documents/gfr$ git commit -m \"Tracking a big file.\"\n(home) user@User-HP ~/Documents/gfr$ for i in {1..10000}; do echo \"Hello world!\" &gt; big_file.txt; done;\n(home) user@User-HP ~/Documents/gfr$ du -h big_file.txt\n128K  big_file.txt\n(home) user@User-HP ~/Documents/gfr$ git add big_file.txt\n(home) user@User-HP ~/Documents/gfr$ git commit -m \"Oooof.\"\n(home) user@User-HP ~/Documents/gfr$ git branch \n* main\n(home) user@User-HP ~/Documents/gfr$ git filter-repo --path big_file.txt --invert-paths\n(home) user@User-HP ~/Documents/gfr$ git log \nfatal: your current branch 'main' does not have any commits yet\n</code></pre>"},{"location":"INSTALLATION/#git-large-file-storage","title":"Git Large File Storage","text":"<p><code>git lfs</code> is a plugin that aims to make working with large file much easier. There documentation is very good and can be accessed using <code>git lfs --help</code>. In summary, <code>git lfs</code> implements a specific type of  <code>git</code> object designed to reduce the amount of disk space that <code>git</code> uses to  store a large file. <code>git</code> normally uses <code>blob</code>s for files but a file tracked  using <code>git lfs</code> stores the file in this special way. </p> <p>To install <code>git lfs</code> you may use your package manager or download the binary  from the website. To use <code>git lfs</code> first run <code>git  lfs install</code> and then <code>git lfs track path/to/big/file</code>. You will notice that this process has produced a new file <code>.gitattributes</code> which <code>git lfs</code> uses  to identify what files it is tracking. From now on <code>git</code> can be used in the normal way.</p>"},{"location":"INSTALLATION/#resources","title":"Resources","text":"<ul> <li>git</li> <li>bitbucket</li> <li>git filter-repo</li> <li>git lfs</li> </ul>"},{"location":"INSTALLATION/#the-github-cli","title":"The Github CLI","text":"<p><code>github</code> is one of many services that provide servers to store <code>git</code>  repostories. To the best of my knowledge it is the largest such service and it also provides a number of useful tools. For example, actions, issues and reviews. The <code>toliman</code> repository is stored on <code>github</code> and can be  installed using <code>git clone https://github.com/ConaireD/TolimanWIP</code>.  I recommend installing the <code>github</code> CLI (<code>gh</code>), because it compliments  a terminal/IDE + terminal workflow. <code>gh</code> can be installed using your  package manager. </p>"},{"location":"INSTALLATION/#using-gh","title":"Using Gh","text":"<p><code>gh</code> is a very modular tool consisting of many command and subcommand  patterns of the form <code>gh command subcommand --option</code>. Moreover, <code>gh</code> is interactive and will prompt you to enter input in a text editor if you do not provide it as an option. <code>gh</code> is a very complex tool but in  general it is most useful for managing <code>issue</code>s and pull requests (<code>pr</code>s).</p> Example<pre><code>(home) user@User-HP ~/Documents/toliman$ gh issue create --title \"Implement an Installation Guide\" --body \"Hi all,\n&gt;As the project nears completion we should make sure that it is easy to use. I think that we \n&gt;should provide a detailed guide on how to set up the project. Not just the basic steps but \n&gt;also a little bit of detail explaining how to use the various tools. This kind of information \n&gt;sharing is crucial to good teamwork.\n&gt;Regards\n&gt;Jordan\" --assignee @me --label documentation\n</code></pre> <p><code>gh issue create</code> tells <code>gh</code> that we are managing our <code>issue</code>s and we  want to <code>create</code> a new one. <code>--title</code> and <code>--body</code> are self explanatory. <code>--assignee</code> tells <code>gh</code> who to assign the issue to, in this case me (using  the shortcut <code>@me</code>). If I wanted to assign someone else to the issue I would type out their <code>github</code> username in full (with no <code>@</code>). For example,  <code>--assignee JohnTheBaconatorOfChristopherColumbus</code>. Fortunately most  usernames are much shorter than my example. </p> <p>To view an <code>issue</code> you must first know its number. To get the number run  <code>gh issue list</code> which will list all the open issues (including their numbers). <code>gh issue list</code> can be used to search via <code>--search</code> and can view <code>issue</code>s  that are closed via <code>--state closed</code>. Once you have the number you can  use <code>gh issue view number --comments</code> to view the entire conversation in the  terminal. If you just want a summary, removing the <code>--comments</code> flag will  just show the first and the last comment. <code>gh label</code> can be used to delete,  edit and create labels.</p>"},{"location":"INSTALLATION/#plugins_1","title":"Plugins","text":""},{"location":"INSTALLATION/#gh-changelog","title":"Gh Changelog","text":"<p><code>gh</code> has many plugins. We only use on <code>gh changelog</code> as it allows us to  easily keep a changelog across our versions. There is some nuance to using this plugin. It uses <code>git tag</code>s to find the versions which are  entered into the changelog. The canges are pulled from the <code>pr</code>s that  have occured in between versions, and rely on the <code>labels</code> assigned to those <code>pr</code>s. However, the tags need to be on <code>github</code> so when <code>push</code>ing changes make sure to use the <code>--follow-tags</code> flag. To create the changelog just run <code>gh changelog new</code> and to view it run <code>gh changelog view</code>.</p>"},{"location":"INSTALLATION/#resources_1","title":"Resources","text":""},{"location":"INSTALLATION/#python","title":"Python","text":"<p>I imagine that you are familiar with <code>python</code>, but for the sake of completeness and consistency it is a dynamicly typed, interpretted-bytecode  language with inbuilt support for functional and object oriented programming.  At present <code>python</code> does not ship with a <code>jit</code> runtime for <code>python</code> bytecode,  but this is scheduled for the <code>python3.12</code> release. <code>python</code> is praised for  its readability and critized for its speed. Since speed is a necessary evil  in our <code>toliman</code> package we are using <code>dLux</code>, which in turn used <code>jax</code>, a  third party <code>python/numpy</code> compiler and sutomatic differentiation framework. At the <code>toliman</code> level you will rarely need to interact with <code>jax</code> directly.</p>"},{"location":"INSTALLATION/#anaconda","title":"Anaconda","text":"<p>Anaconda or <code>conda</code> is a popular distribution of <code>python</code> that ships within  a virtual environment manager. We used <code>conda</code> to develop <code>toliman</code> and  recommend it to others who are involved on the project. A virtual environment provides a pointer to a set of executables and packages, ensuring that once  the environment is activated the versions it points to are used. This is most useful when developing multiple packages, with different versions of shared dependancies.  </p>"},{"location":"INSTALLATION/#installing-anaconda","title":"Installing Anaconda","text":"<p>To install anaconda you will need to download the installer from the  Anaconda website. Follow  the installation instructions specific to your operating system from there  onwards. On MacOS/Linux you will need to execute the downloaded <code>bash</code>  script using <code>bash path/to/script</code> and it will do the rest for you. I  believe that it is safe to remove the script once <code>conda</code> is installed.</p>"},{"location":"INSTALLATION/#using-anaconda","title":"Using Anaconda","text":"<p>Imagine you are developing <code>toliman</code> which uses <code>python3.10.8</code>, and also  developing <code>steampunkfairytale</code> which uses <code>python3.8</code>. You can create an environment for each and switch between as needed. </p> <p>??? example:</p> <pre><code>```bash\n(home) user@Users-HP: ~/Documents$ conda create toliman python=3.10.8 \n(home) user@Users-HP: ~/Documents$ conda activate toliman\n(toliman) user@Users-HP: ~/Documents$ cd toliman\n(toliman) user@Users-HP: ~/Documents/toliman$ echo \"Developing toliman ... Done!\"\nDeveloping toliman ... Done!\n(toliman) user@Users-HP: ~/Documents/toliman$ conda deactivate\n(home) user@Users-HP: ~/Documents/toliman$ cd ..\n(home) user@Users-HP: ~/Documents$ conda create steampunckfairytale python=3.8\n(home) user@Users-HP: ~/Documents$ conda activate steampunkfairytale \n(steampunkfairytale) user@Users-HP: ~/Documents$ cd spft\n(steampunkfairytale) user@Users-HP: ~/Documents/spft$ echo \"Developing steampunkfairytale ... Done!\"\nDeveloping steampunkfairytale ... Done!\n(steampunkfairytale) user@Users-HP: ~/Documents/spft$ conda deativate steampunkfairytale\n(home) user@Users-HP: ~/Documents/spft$ cd ..\n(home) user@Users-HP: ~/Documents$ \n```\n</code></pre> <p><code>conda</code> also comes with a package manager (similar to <code>pypi</code> + <code>pip</code>), which  can be used to install packages. The interface is more or less the same  as <code>pip</code> which is <code>python</code>s default package manager. I am assuming familiary with <code>pip</code> but if you need more information the  documentation is very good.</p>"},{"location":"INSTALLATION/#resouces","title":"Resouces","text":"<ul> <li>Anaconda</li> </ul>"},{"location":"INSTALLATION/#poetry","title":"Poetry","text":"<p>Dependencies are third party libraries used by a package. Quite often  dependancies contribute to software bloat, because although the entire  library needs to be installed you may only use/need a small subset. As a goal of modern development is modularity. Every dependency tries to do  only one thing (OK not quite one thing), with a clear purpose. This  creates its own problems, since now many small dependencies are needed  which in turn may depend on each other or yet more dependencies. Depending on whether or not dependcies are actively maintained, your dependencies  can come to rely upon different versions often within some window. You  can imagine that for any sizeable project downloading compatible versions of the dependencies can become an ourtight nightmare. </p> <p><code>pip</code> the default <code>python</code> package manager has some very basic dependancy  management functionality, but for the most part it is superficial; printed  warnings etc. Although <code>toliman</code> is a small package by software standards  however, <code>jax</code>, which is a dependancy of <code>dLux</code> is under rapid development publishing many new versions over the lifetime of the project. This is one way that dependencies can become incompatible, because changes in the <code>jax</code> API may break packages that use it (for example <code>dLux</code>). It is common when  developing <code>python</code> projects to use <code>pip</code> since it is not a dependency and  provides most of the necessary functionality. However, due to our past  experiences with <code>jax</code> we chose to use the more modern tool <code>poetry</code>.</p> <p>Most modern programming languages come with a dependancy management tool, for <code>python</code> this is <code>poetry</code>. <code>poetry</code>, as I aluded to in the paragraph  above is ironically a third party tool and hence a dependency itself.  By and large dependency management tools are able to automatically select  the correct versions of packages too install preventing this type of  development headache. Moreover, <code>poetry</code> also simplifies other common  processes such as <code>install</code>ing, <code>build</code>ing and <code>publish</code>ing. When working  with <code>toliman</code>, you are unlikely to require much familiarity with <code>poetry</code>  as most/all of the dependencies are already established.</p>"},{"location":"INSTALLATION/#installing-poetry","title":"Installing Poetry","text":"<p>Unfortunately, <code>poetry</code> cannot yet be installed using a package manager  so you will need to download it from the internet. On MacOS/Linux <code>poetry</code>  can be installed using <code>curl -sSL https://install.python-poetry.org | python3 -</code>.</p>"},{"location":"INSTALLATION/#using-poetry","title":"Using Poetry","text":"<p>This guide is very cursory, since it is unlikely you will need to use  <code>poetry</code> much in your development journey with toliman. The first useful  command is <code>poetry show package</code>. This will print useful information about the package you selected. In fact, it will even print in color! Let's imagine that you have stumbled across a new package that you think <code>toliman</code> will benfit from. You decide to use it. To register it as a dependency run  <code>poetry add package</code> and <code>poetry</code> will automatically find a version that is  compatible with the existing versions and install it. How does <code>poetry</code> work?  You may notice the <code>pyproject.toml</code> file in the root directory of <code>toliman</code>.  This is the file that <code>poetry</code> uses to manage/track the dependencies of  <code>toliman</code>. </p> Aside<p><code>python</code> dependency management has incrementally evolved in the thirty  odd years of the languages lifetime. I'm not sure of the early years  but after some time the <code>setuptools</code> package was created in the standard  library, which could be used to specify a <code>build</code> within a <code>python</code> script called <code>setup.py</code>. While this allowed for some powerful metaprogramming for experienced users, in general the interface was messy. Somewhere around  this time <code>build</code> tools for other languages were increasingly handling  dependencies. For example, <code>ant</code> inspired <code>maven</code> in the <code>java</code> ecosystem, which is both a build tool and full blown dependency manager. Over this  period a very large number of markup languages were created, providing  well defined syntaxes. Build tools and dependency management tools  increasingly started to leverage markup languages instead of implementing  domain specific languages for their purposes. Eventually, <code>rust</code> released  along with a <code>cargo</code>, a dependency management and build tool.  <code>cargo</code> used the <code>toml</code> markup language as the interface to its dependency specification. Furthermore, <code>cargo</code> also took things one step further and automated many processes, so the typical  user never interacted with the <code>cargo.toml</code>. The <code>poetry</code> interface is very similar to the <code>cargo</code> one.</p> <p>To install the dependencies for <code>toliman</code> simply run <code>poetry install</code>. This will take a while so make sure you have a coffee and a good book nearby. By default this will install <code>toliman</code> in development mode. This just means  that instead of placing a <code>.whl</code> file in the <code>conda</code> environment, <code>poetry</code>  has placed a file pointing to the code itself. This is very handy because  it means that any changes you make instantly become effective even when  using the installed version. To fully install <code>toliman</code> run <code>poetry build</code>. This will create a <code>dist</code> directory, containing two files. One will be a  <code>.whl</code>, the other a <code>.tar.gz</code>. We only care about the the <code>.whl</code>. To install  the <code>.whl</code> use <code>pip install dist/name.whl</code>.</p> <p><code>poetry</code> facilitates the grouping of dependencies. This can be very useful, but is often unecessary. For example, imagine you are developing a package that groups its dependencies by <code>tests</code>, <code>core</code>, and <code>documentation</code>. You  may just be using the package and do not plan to modify the code or  documentation. In this case <code>poetry install --group core</code> would install  only the dependencies required to use the package, saving disk space  and a little time. You can add dependencies to a new group using <code>poetry  add --group group-name</code>. </p> <p>Say you are using several dependencies to manage your documentation. As  you learn more about these dependencies you discover there is a lot of  overlapping functionality between them. In the end you discover that  you can acheive the same results using half the number of dependencies. <code>poetry</code> makes removing dependencies as easy as <code>poetry remove dependency</code> which will uninstall dependency and remove it from the <code>pyproject.toml</code>.</p>"},{"location":"INSTALLATION/#resources_2","title":"Resources","text":"<ul> <li>https://python-poetry.org/docs/</li> </ul>"},{"location":"INSTALLATION/#pytest","title":"Pytest","text":"<p>Code validity is very important in modern software development. Modern  programming languages are increasingly incorporating features to make  programming safer and more provable. For example, <code>SPARK</code> a subset of  <code>Ada</code> implements a contracts to guarantee compile time saftey. <code>rust</code> is another example, implementing a borrowing API for sharing information  that makes it almost impossible to get memory leaks. There is also  a steady shift towards the functional programming paradigm, which, among  other things, minimises side effects. </p> Side Effects<p>A side effect is a change in the state of a program that is not  explicitly returned. A program cannot do anything without side  effects but they are a common cause of runtime errors.</p> <p><code>python</code>, being an older language, does not implement many of these  more modern features. As a result we have to check the validity of our code the old fashioned way: rigorous testing. Like most languages  <code>python</code> has several third party implementations of testing frameworks.  For the <code>toliman</code> project, we chose <code>pytest</code>. </p> Why <code>pytest</code><p>A common naming convention for testing frameworks is <code>xUnit</code>, where <code>x</code> specifies the programming language. For example, <code>jUnit</code> for  <code>java</code>. These pacakges usually implement a setup-teardown design. You program a function to setup the test/tests and one to tear it down. This can quickly become too rigid, preventing you from using  multiple setup functions. <code>pytest</code> implements a different interface inspired by the percieved failings of the <code>xUnit</code> ecosystems.</p> <p><code>pytest</code> is a very flexible framework. It can be invoked using <code>pytest</code> and will automatically detect tests based on file and function/class names. Alternatively you can run it on a specific file using <code>pytest path/to/file</code>. It allows you to single out test classes and even test functions using  <code>pytest path/to/file::TestClass::test_function</code>. If that was not flexible  enough you can run tests using a keyword search via the <code>-k</code> flag. </p> <p>A <code>fixture</code> is a <code>pytest</code> artifact used to setup and teardown tests.  <code>fixture</code>s are flexible since they can be requested by any other <code>fixture</code>  or any other test. This modularity can make testing code much simpler.  However, <code>fixture</code>s are not treated like a regular function. Instead  they are executed once and cached when they are requested. In a world  devoid of side effects this would be fine, but when they become necessary  this can cause problems. <code>fixture</code>s are executed in the order that they are requested so be careful.</p> <p>Note</p> <p><code>pytest</code> leverages the <code>assert</code> keyword to determine if a test passes. A test can fail and assertion or it can fail because there was an error.  Tests that use <code>assert</code> are more useful for checking the code is correct.</p> Fixtures in the Wild<pre><code>import pytest\n\n@pytest.fixture\ndef letters_of_the_alphabet() -&gt; list:\n    return [chr(i) for i in range(97, 123)]\n\ndef test_str_upper_on_lower_case(letters_of_the_alphabet: list) -&gt; None:\n    for char in letters_of_alphabet:\n        assert char.upper().isupper()\n</code></pre> <p>This test is would evaluate as  <code>test_str_upper_on_lower_case(letter_of_the_world())</code>. In fact, we  can use another <code>pytest</code> feature to improve this test. In general  it is advised that every unit test should test a single case, we are  testing twenty-six. <code>pytest.mark.parametrize</code> is similar to the inbuilt <code>map</code> function, but creates unique tests for each case. Using the example from earlier,</p> <pre><code>import pytest\n\n@pytest.mark.parametrize(\"char\", [chr(i) for i in range(97, 123)])\ndef test_str_upper_on_lower_case(char: chr) -&gt; None:\n    assert char.upper().isupper()\n</code></pre> <p>If you on the ball you may have noticed that all <code>fixture</code>s are evaluated  before the test is executed. This can lead to problems when tests involve  side effects. As a result using <code>yield</code> in a <code>fixture</code> will cause the  code after <code>yield</code> to evaluate once the test has finished. We have used  this feature extensively in the development of <code>toliman</code>, since we deal  with a lot of file operations. </p> <code>yield</code> in <code>fixture</code>s<p><pre><code>import pytest\n\n@pytest.fixture\ndef print_info() -&gt; None:\n    print(\"&gt;&gt;&gt;\")\n    yield\n    print(\"&lt;&lt;&lt;\")\n\ndef test(print_info: None) -&gt; None:\n    print(\"TEST\")\n</code></pre> Will output  <pre><code>&gt;&gt;&gt;\nTEST\n&lt;&lt;&lt;\n</code></pre></p> Writing Unit Tests<p>You should not have to write many unit tests for <code>toliman</code>, since they  have been programmed already. If you do have to write some unit tests  however, there are two guidlines that are helpful to remember: a)  FIRST and b) AAAC. FIRST lists the features of a good unit test and AAAC explains how one may implement such a test. </p> <p>FIRST - Fast: Typically there are many more tests than functions. Especially              if you each test is specific to a single case. In a standard              workflow the tests are run to validate any new changes. If             each test takes a macropspic amount of time, no one will use              the tests and they become redundant. - Independent: Each test should be a single unit (its in the name).                    This way the success or failure of a test does not                     depend on the other tests. - Repeatable: Nothing is more frustrating than getting different                    results on different machines. Ideally, tests should                    not rely on system specific code, making debugging in                    a mixed team easier. - Self-validating: This just means that the tests should pass or fail                         without the tester having to check. This sounds                         silly, but for complex outputs it can be difficult                        to automatically determine if they are correct.  - Thorough: This should be obvious, tests are not that useful if                  they only catch some of the bugs. Again, implementing                  thorough tests is time consuming and can often feal                 very unrewarding.</p> <p>AAAC - Arrange: Set up the evironment of the test. - Act: Perform the test action. - Assert: Check if the test action produced the correct output. - Clean Up: Revert any side effects or free memory.</p>"},{"location":"INSTALLATION/#plugins_2","title":"Plugins","text":"<p><code>pytest</code> is popular, so users have created plugins to enhance the functionality as they needed. We use several plugins for <code>toliman</code> but none are strictly necessary. </p>"},{"location":"INSTALLATION/#pytest-xdist","title":"Pytest Xdist","text":"<p><code>pytest-xdist</code> lets us run our tests across multiple processes. This plugin helps us make our unit tests fast (FIRST). Some of the  programs we are testing are necessarily time consuming so running them in parallel is very useful. Unfortunately it is difficult to use this  plugin when the tests have side effects. In general side effects make test co-dependent (FIRST). To invoke tests in a parallel way use  <code>pytest ... -n num_processes</code>. The only tests in the <code>toliman</code> test  suite that can be run on separate processes are the tests in  <code>tests/test_toliman.py</code>.</p>"},{"location":"INSTALLATION/#pytest-timer","title":"Pytest Timer","text":"<p><code>pytest-timer</code> is a reporting tool. It tells us how long each test took. This helps with FIRST by letting us identify which tests/functions  need to be optimised or isolated. Once installed the plugin justs  adds a table to the <code>pytest</code> ouput and you are not required to interact  with it in any way. </p> <p>Tip</p> <p>Some things are going to be slow. Not every program can be written so  that it executes in a fraction of a second. We can identify tests  that are slow using <code>pytest.mark.slow</code>. We can then leave these tests out when running pytest using <code>pytest ... -m \"not slow\"</code>. </p>"},{"location":"INSTALLATION/#pytest-cov","title":"Pytest Cov","text":"<p><code>pytest-cov</code> addresses FIRST. It shows us how much of our code is  tested. Like <code>pytest-timer</code> it is a diagnostics tool. To generate a  coverage report add the <code>--cov</code> flag to your <code>pytest</code> call. This will  be ouput in the terminal giving a percentage by file. If you wish to  see exactly where is not tested it can be used to generate a <code>html</code>  report showing what lines were and were not tested.</p>"},{"location":"INSTALLATION/#pytest-sugar","title":"Pytest Sugar","text":"<p>While most of the plugins that we recommend have some functional value, <code>pytest-sugar</code> purely aesthetic. This plugin beautifies the ouput of  <code>pytest</code> and runs automatically once installed. I highly recommend it if you plan to be running the tests much.</p>"},{"location":"INSTALLATION/#resources_3","title":"Resources","text":"<ul> <li>https://docs.pytest.org/en/7.1.x/contents.html</li> <li>https://pytest-xdist.readthedocs.io/en/latest/</li> <li>https://pytest-cov.readthedocs.io/en/latest/</li> <li>https://pypi.org/project/pytest-timer/</li> <li>https://pypi.org/project/pytest-sugar/</li> </ul>"},{"location":"INSTALLATION/#mkdocs","title":"Mkdocs","text":"<p>We have used <code>mkdocs</code> to generate our documentation. <code>mkdocs</code> makes it easy  to produce high quality static documentation without too much hassle, turning  markdown files into a website. <code>mkdocs</code> reads markdown files and configures  the website from a <code>yaml</code> file; <code>mkdocs.yml</code>. While <code>mkdocs</code> forms the backbone of our documentation engine we are using a number of plugins that make the  interface entirely alien from vanilla <code>mkdocs</code>. We have chosen to use <code>mkdocs</code>  in this way to adhere to the concept of literate programming. To this end we  use the plugins <code>mkdocs-same-dir</code>, <code>mkdocs-simple</code> and <code>mkdocstrings</code>.</p> Vanilla <code>mkdocs</code> and Literate Programming<p>If you we to start developing a new package tomorrow using <code>poetry</code>  and <code>mkdocs</code>, you could quite simply do:</p> <pre><code>(home) user@Users-HP ~/Documents$ mkdocs new mypackage &amp;&amp; cd mypackage\n(home) user@Users-HP ~/Documents/mypackage$ poetry init .  </code></pre> <p>Then you could type your documentation in the automatically generated  <code>docs</code> folder using markdow and view it using <code>mkdocs serve</code>. The  problem with this is that if your API changes you have to manually change this in the documentation. If your API is internally documented  using docstrings this means that your work is doubled. Literate  programming is about recognising that documentation is just as important to programming as actually writing code is. </p> <p>In particular, one of the goals of literate programming is to provide  the documentation in the same place as the body of the code. Most languages implement this via docstrings/multiline comments, and it may be formalised  further by additional tools. <code>java</code> is a good example, the <code>java</code>  development kit containing <code>javadoc</code> a tool to automatically render  documentation websites from commented code. For us, <code>mkdocstrings</code> and <code>mkdocs-simple</code> provide the means to implement literate programming.</p>"},{"location":"INSTALLATION/#plugins_3","title":"Plugins","text":""},{"location":"INSTALLATION/#mkdocs-same-dir","title":"Mkdocs Same Dir","text":"<p><code>mkdocs-same-dir</code> let's us write our documentaton in the same directory as  our code. simplifies the structure of the package and more closely ties the  documentation (and its structure) to the code of the package. Once installed <code>mkdocs-same-dir</code> is very easy to use. Opening the <code>mkdocs.yml</code> add the  following line lines to your <code>mkdocs.yml</code></p> <pre><code>docs_dir: .\n\nplugins:\n- same-dir\n</code></pre>"},{"location":"INSTALLATION/#mkdocs-simple","title":"Mkdocs Simple","text":"<p>Like <code>mkdocs-same-dir</code>, <code>mkdocs-simple</code> is easy to use. It tells <code>mkdocs</code>  not just to look for markdown files, but also to look for source files  containing multiline comments/strings with the <code>md</code> flag. To use it  add the following line to your <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- simple\n</code></pre> Example<pre><code># src/https.py\n\"\"\"md\n## Overview\nThis package interacts extensively with the internet. Due to the nature \nof the product we enforce long timeout thresholds and high retry counts.\nTo make sure that this is enforced we provide an interface (via requests)\nthat is used internally. This is managed via the ..\n\"\"\"\nimport requests\n\nclass HttpRequest(requests.Request):\n\"\"\"\n    \"\"\"\n</code></pre> <p>In most cases this can avoid the creation of overview files for  submodules. While it is handy, it is easy to overuse and I would  recommend caution when chosing whether or not to use it.</p>"},{"location":"INSTALLATION/#mkdocstrings","title":"Mkdocstrings","text":"<p><code>mkdocstrings</code> is used to automatically generate documentation from docstrings. This is extremely handy and can be combined with <code>mkdocs-simple</code> to great  affect. When using <code>mkdocstrings</code> with vanilla <code>mkdocs</code> you would have to  create a file in <code>docs/submodule/myclass.py</code> and add into it  <code>::: src.submodule.MyClass</code>. This can quickly get out of hand, and you  end up with all these practically empty markdown files. When using simple  it can be done in place. Let's revisit my earlier example.</p> Example<pre><code># src/https.py\n\"\"\"md\n## Overview\nThis package interacts extensively with the internet. Due to the nature \nof the product we enforce long timeout thresholds and high retry counts.\nTo make sure that this is enforced we provide an interface (via requests)\nthat is used internally. This is managed via the ..\n\n::: src.hhtps.HttpRequest\n\"\"\"\nimport requests\n\nclass HttpRequest(requests.Request):\n\"\"\"\n    \"\"\"\n</code></pre> <p>Now <code>mkdocs</code> will not only output the overview, but also the fully  documented API of the <code>HttpRequest</code> class.</p> <p>Unfortunately, it can be quite difficult to setup <code>mkdocstrings</code>, since they tried to make it a more general tool, for multiple languages. As a  result you have to specify different handlers. For <code>toliman</code> we are using  the <code>mkdocstrings-python-legacy</code> version, since this uses <code>pytkdocs</code> as  the backend. I chose this version because it allows documentation to  be inherited from parent classes. To use <code>mkdocstrings</code>, add the following  to your <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- mkdocstrings\n</code></pre>"},{"location":"INSTALLATION/#mkdocs-material","title":"Mkdocs Material","text":"<p>Yay! We have generated some documentation in a way that adheres to the rules of literate programming. Now we are confronted with a very severe problem.  They are ugly and generic. Just as <code>pytest-sugar</code> was purely aesthetic  <code>mkdocs-materical</code> is solely about improving the look and feal of the  documentation. This is a theme for <code>mkdocs</code> and it can be configured with:</p> <pre><code>theme:\nname: material\n</code></pre>"},{"location":"INSTALLATION/#resources_4","title":"Resources","text":"<ul> <li>https://www.mkdocs.org/ </li> <li>https://squidfunk.github.io/mkdocs-material/</li> <li>https://mkdocstrings.github.io/</li> <li>https://www.althack.dev/mkdocs-simple-plugin/v2.2.0/</li> <li>https://oprypin.github.io/mkdocs-same-dir/</li> </ul>"},{"location":"LICENSE/","title":"LICENSE","text":"<p>Copyright 2023 ConaireD, Jordan Dennis and Peter Tuthill</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files, to deal in the Software without restriction, including without limitation to the rights of use, copy, modify, merge, publish, distribute, and sub-license copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to  the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in  all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGMENT. IN NO EVENT SHALL THE  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE  SOFTWARE.</p>"},{"location":"toliman/overview/","title":"Overview","text":""},{"location":"toliman/overview/#overview","title":"Overview","text":"<p>This will be an overview with some deatiled end to end examples.</p> <p>         Bases: <code>dl.Optics</code>, <code>collections.CollectionInterface</code></p> <p>Simulates the optical system of the TOLIMAN telescope.</p> <p>It is designed to occupy the <code>optics</code> kwarg of <code>dl.Instrument</code>. The <code>TolimanOptics</code> provides a default implementation that can be extended using the <code>.add</code> method. There are also several ways that the <code>TolimanOptics</code> can be initialised.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; toliman_optics: object = TolimanOptics()\n&gt;&gt;&gt; toliman_optics: object = TolimanOptics(simulate_aberrations = False)\n&gt;&gt;&gt; toliman_optics: object = TolimanOptics(pixels_in_pupil = 1024)\n</code></pre> <p>For more options run <code>help(TolimanOptics.__init__)</code>.</p> <p>Simulate the Toliman telescope.</p> <p>Parameters:</p> Name Type Description Default <code>simulate_polish</code> <code>bool</code> <p>True if a layer should be included simulating the polish on the secondary mirror.</p> <code>False</code> <code>simulate_aberrations</code> <code>bool</code> <p>True if the aberrations should be included.</p> <code>True</code> <code>operate_in_fresnel_mode</code> <code>bool</code> <p>True if the simulation should use Fresnel instead of Fourier optics.</p> <code>False</code> <code>operate_in_static_mode</code> <code>bool</code> <p>True if the pupil of the aperture should be modelled as static. This will improve performance so only change it if you want to learn a parameter of the aperture.</p> <code>True</code> <code>number_of_zernikes</code> <code>int</code> <p>The number of zernike polynomials that should be used to model the aberrations.</p> <code>int(os.environ['DEFAULT_NUMBER_OF_ZERNIKES'])</code> <code>pixels_in_pupil</code> <code>int</code> <p>The number of pixels in the pupil plane.</p> <code>int(os.environ['DEFAULT_PUPIL_NPIX'])</code> <code>pixels_on_detector</code> <code>int</code> <p>The number of pixels in the detector plane.</p> <code>int(os.environ['DEFAULT_DETECTOR_NPIX'])</code> <code>path_to_mask</code> <code>str</code> <p>The file location of a <code>.npy</code> file that contains an array representation o the mask.</p> <code>os.environ['DEFAULT_MASK_DIR']</code> <code>path_to_filter</code> <code>str</code> <p>The file location of a <code>.npy</code> file that contains an array representation og the filter.</p> <code>'assets/filter.npy'</code> <code>path_to_polish</code> <code>str</code> <p>The file location of a <code>.npy</code> file that contains an array representation of the secondary mirror polish.</p> <code>'assets/polish.npy'</code> <p>         Bases: <code>dl.Detector</code>, <code>collections.CollectionInterface</code></p> <p>Represents the Toliman detector.</p> <p>A default implementation of a generic detector that is designed to be used with the <code>dLux.Instrument</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; toliman_detector: object = TolimanDetector()\n&gt;&gt;&gt; toliman_detector: object = TolimanDetector(simulate_jitter = False)\n</code></pre> <p>Simulate the Toliman detector.</p> <p>Parameters:</p> Name Type Description Default <code>simulate_jitter</code> <code>bool</code> <p>True if jitter should be included in the simulation of the detector.</p> <code>True</code> <code>simulate_pixel_response</code> <code>bool</code> <p>True if a pixel response should be included in the simulation of the detector.</p> <code>True</code> <code>simulate_saturation</code> <code>bool</code> <p>True if staturation should be included in the simulation of the detector.</p> <code>True</code> <code>extra_detector_layers</code> <code>list</code> <p>Extra detector effects besides the default ones.</p> <code>[]</code> <p>         Bases: <code>dl.BinarySource</code></p> <p>A convinient representation of the Alpha Centauri binary system.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; alpha_cen: object = AlphaCentauri()\n&gt;&gt;&gt; wavelengths: float = 1e-09 * np.linspace(595., 695., 10)\n&gt;&gt;&gt; fluxes: float = np.ones((10,), dtype = float)\n&gt;&gt;&gt; spectrum: object = dl.ArraySpectrum(wavelengths, fluxes)\n&gt;&gt;&gt; alpha_cen: object = AlphaCentauri(spectrum = spectrum)\n</code></pre> <p>Simulate Alpha Centauri.</p> <p>Parameters:</p> Name Type Description Default <code>spectrum</code> <code>float</code> <p>A <code>dl.Spectrum</code> if the default is not to be used. Recall that the convinience method <code>_simulate_alpha_cen_spectrum</code> can be used to simulate the spectrum.</p> <code>None</code> <p>         Bases: <code>dl.MultiPointSource</code></p> <p>Simplies the creation of a sample of background stars.</p> <p>The sample of background stars is pulled from the Gaia database but there is some voodoo involved in regularising the data. Use the <code>_simulate_background_stars</code> function to generate alternative samples.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bg: object = Background()\n&gt;&gt;&gt; lim_bg: object = Background(number_of_bg_stars = 10)\n</code></pre> <p>Simulate background stars.</p> <p>Parameters:</p> Name Type Description Default <code>number_of_bg_stars</code> <code>int</code> <p>How many background stars should be simulated.</p> <code>None</code> <code>spectrum</code> <code>object</code> <p>A <code>dl.Spectrum</code> if the default spectrum is not to be used.</p> <code>None</code>"},{"location":"toliman/overview/#toliman.toliman.TolimanOptics.insert","title":"<code>insert(optic, index)</code>","text":"<p>Add an additional layer to the optical system.</p> <p>Parameters:</p> Name Type Description Default <code>optic</code> <code>object</code> <p>A <code>dLux.OpticalLayer</code> to include in the model.</p> required <code>index</code> <code>int</code> <p>Where in the list of layers to add optic.</p> required <p>Returns:</p> Name Type Description <code>toliman</code> <code>TolimanOptics</code> <p>A new <code>TolimanOptics</code> instance with the applied update.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanOptics.remove","title":"<code>remove(index)</code>","text":"<p>Take a layer from the optical system.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Where in the list of layers to remove an optic.</p> required <p>Returns:</p> Name Type Description <code>toliman</code> <code>TolimanOptics</code> <p>A new <code>TolimanOptics</code> instance with the applied update.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanOptics.pop","title":"<code>pop()</code>","text":"<p>Remove the last element in the optical system.</p> <p>Please note that this differs from the <code>.pop</code> method of the <code>list</code> class  because it does not return the popped element.</p> <p>Returns:</p> Name Type Description <code>optics</code> <code>object</code> <p>The optical system with the layer removed.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanOptics.append","title":"<code>append(optic)</code>","text":"<p>Place a new optic at the end of the optical system.</p> <p>Parameters:</p> Name Type Description Default <code>optic</code> <code>object</code> <p>The optic to include. It must be a subclass of the <code>dLux.OpticalLayer</code>.</p> required <p>Returns:</p> Name Type Description <code>optics</code> <code>object</code> <p>The new optical system.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanDetector.append","title":"<code>append(optic)</code>","text":"<p>Place a new optic at the end of the optical system.</p> <p>Parameters:</p> Name Type Description Default <code>optic</code> <code>object</code> <p>The optic to include. It must be a subclass of the <code>dLux.OpticalLayer</code>.</p> required <p>Returns:</p> Name Type Description <code>optics</code> <code>object</code> <p>The new optical system.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanDetector.insert","title":"<code>insert(optic, index)</code>","text":"<p>Add an additional layer to the optical system.</p> <p>Parameters:</p> Name Type Description Default <code>optic</code> <code>object</code> <p>A <code>dLux.OpticalLayer</code> to include in the model.</p> required <code>index</code> <code>int</code> <p>Where in the list of layers to add optic.</p> required <p>Returns:</p> Name Type Description <code>toliman</code> <code>TolimanOptics</code> <p>A new <code>TolimanOptics</code> instance with the applied update.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanDetector.pop","title":"<code>pop()</code>","text":"<p>Remove the last element in the optical system.</p> <p>Please note that this differs from the <code>.pop</code> method of the <code>list</code> class  because it does not return the popped element.</p> <p>Returns:</p> Name Type Description <code>optics</code> <code>object</code> <p>The optical system with the layer removed.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanDetector.remove","title":"<code>remove(index)</code>","text":"<p>Take a layer from the optical system.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Where in the list of layers to remove an optic.</p> required <p>Returns:</p> Name Type Description <code>toliman</code> <code>TolimanOptics</code> <p>A new <code>TolimanOptics</code> instance with the applied update.</p>"},{"location":"toliman/overview/#toliman.toliman.TolimanDetector.to_optics_list","title":"<code>to_optics_list()</code>","text":"<p>Get the optical elements that make up the object as a list.</p> <p>Returns:</p> Name Type Description <code>optics</code> <code>list</code> <p>The optical layers in order in a list.</p>"}]}